{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from turtlesim_enacter import TurtleSimEnacter # requires ROS\n",
    "from turtlepy_enacter import TurtlePyEnacter\n",
    "# from Agent5 import Agent5\n",
    "# from OsoyooCarEnacter import OsoyooCarEnacter\n",
    "ROBOT_IP = \"192.168.4.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, valence_table):\n",
    "        \"\"\" Creating our agent \"\"\"\n",
    "        self.valence_table = valence_table\n",
    "        self._action = None\n",
    "        self.anticipated_outcome = None\n",
    "\n",
    "    def action(self, outcome):\n",
    "        \"\"\" tracing the previous cycle \"\"\"\n",
    "        if self._action is not None:\n",
    "            print(\"Action: \" + str(self._action) +\n",
    "                  \", Anticipation: \" + str(self.anticipated_outcome) +\n",
    "                  \", Outcome: \" + str(outcome) +\n",
    "                  \", Satisfaction: (anticipation: \" + str(self.anticipated_outcome == outcome) +\n",
    "                  \", valence: \" + str(self.valence_table[self._action][outcome]) + \")\")\n",
    "\n",
    "        \"\"\" Computing the next action to enact \"\"\"\n",
    "        # TODO: Implement the agent's decision mechanism\n",
    "        self._action = 0\n",
    "        # TODO: Implement the agent's anticipation mechanism\n",
    "        self.anticipated_outcome = 0\n",
    "        return self._action\n",
    "    \n",
    "class AgentBoring(Agent) :\n",
    "    def __init__(self,valences_table,steps_until_bored) :\n",
    "        super().__init__(valences_table)\n",
    "        self.step_until_bored = steps_until_bored\n",
    "        self.step = 0\n",
    "        self.actualAction = 0\n",
    "        self.memory = dict \n",
    "\n",
    "    def guessOutcome(self,action) :\n",
    "        outcomesCount = {}\n",
    "        count = 0\n",
    "        for outcome in self.memory[action] : \n",
    "            count += 1\n",
    "            outcomesCount[outcome] += 1\n",
    "        \n",
    "        for outcome in outcomesCount :\n",
    "            outcomesCount[outcome] = outcomesCount[outcome] / count\n",
    "        \n",
    "        rand = Random.random()\n",
    "        sum = 0\n",
    "        for outcome in outcomesCount : \n",
    "            sum += outcomesCount[outcome]\n",
    "            if sum > rand :\n",
    "                return outcome\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def action(self, outcome) :\n",
    "        \"\"\" tracing the previous cycle \"\"\"\n",
    "        if self._action is not None:\n",
    "            print(\"Action: \" + str(self._action) +\n",
    "                  \", Anticipation: \" + str(self.anticipated_outcome) +\n",
    "                  \", Outcome: \" + str(outcome) +\n",
    "                  \", Satisfaction: (anticipation: \" + str(self.anticipated_outcome == outcome) +\n",
    "                  \", valence: \" + str(self.valence_table[self._action][outcome]) + \")\")\n",
    "\n",
    "        \"\"\" Computing the next action to enact \"\"\"\n",
    "        # TODO: Implement the agent's decision mechanism\n",
    "        if self.step > 1 : \n",
    "            self.memory[self.actualAction] += [self.actualAction]\n",
    "            self.step += 1\n",
    "            if self.step % self.step_until_bored != 0 :\n",
    "                self.anticipated_outcome = self.guessOutcome(self.currentAction)\n",
    "\n",
    "\n",
    "        else : \n",
    "            self.step += 1 \n",
    "            self.anticipated_outcome = 0\n",
    "            return self.actualAction\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        # TODO: Implement the agent's anticipation mechanism\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment1:\n",
    "    \"\"\" In Environment 1, action 0 yields outcome 0, action 1 yields outcome 1 \"\"\"\n",
    "    def outcome(self, action):\n",
    "        # return int(input(\"entre 0 1 ou 2\"))\n",
    "        if action == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Environment3:\n",
    "    \"\"\" Environment 3 yields outcome 1 only when the agent alternates actions 0 and 1 \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" Initializing Environment3 \"\"\"\n",
    "        self.previous_action = 0\n",
    "\n",
    "    def outcome(self, action):\n",
    "        _outcome = 1\n",
    "        if action == self.previous_action:\n",
    "            _outcome = 0\n",
    "        self.previous_action = action\n",
    "        return _outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AgentBoring' object has no attribute 'memory'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/shloai/projetProg/m2IA/TestROS/world.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/shloai/projetProg/m2IA/TestROS/world.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m valences \u001b[39m=\u001b[39m [[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m], [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m]]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/shloai/projetProg/m2IA/TestROS/world.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# valences = [[1, -1], [1, -1]]\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/shloai/projetProg/m2IA/TestROS/world.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# TODO Choose an agent\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/shloai/projetProg/m2IA/TestROS/world.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m a \u001b[39m=\u001b[39m AgentBoring(valences,\u001b[39m4\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/shloai/projetProg/m2IA/TestROS/world.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# a = Agent5(valences)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/shloai/projetProg/m2IA/TestROS/world.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# TODO Choose an environment\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/shloai/projetProg/m2IA/TestROS/world.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m e \u001b[39m=\u001b[39m Environment1()\n",
      "\u001b[1;32m/home/shloai/projetProg/m2IA/TestROS/world.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shloai/projetProg/m2IA/TestROS/world.ipynb#W4sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shloai/projetProg/m2IA/TestROS/world.ipynb#W4sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactualAction \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/shloai/projetProg/m2IA/TestROS/world.ipynb#W4sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AgentBoring' object has no attribute 'memory'"
     ]
    }
   ],
   "source": [
    "# TODO Define the valance of interactions (action, outcome)\n",
    "valences = [[-1, 1], [-1, 1]]\n",
    "# valences = [[1, -1], [1, -1]]\n",
    "# TODO Choose an agent\n",
    "a = AgentBoring(valences,4)\n",
    "# a = Agent5(valences)\n",
    "# TODO Choose an environment\n",
    "e = Environment1()\n",
    "# e = Environment2()\n",
    "# e = Environment3()\n",
    "# e = TurtleSimEnacter()\n",
    "# e = TurtlePyEnacter()\n",
    "# e = OsoyooCarEnacter(ROBOT_IP)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \"\"\" The main loop controlling the interaction of the agent with the environment \"\"\"\n",
    "    outcome = 0\n",
    "    for i in range(20):\n",
    "        action = a.action(outcome)\n",
    "        outcome = e.outcome(action)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
